{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a959041f",
   "metadata": {},
   "source": [
    "# Reducing Hospital Readmission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993a82fb",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "\n",
    "1. Itroduction\n",
    "2. Executive summary\n",
    "3. Data and Methods\n",
    "4. Expolratory Data Analysis (EDA) \n",
    "5. Further consideration\n",
    "6. Conclusions and Recommendations\n",
    "7. Annex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268f7f49",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Hospital readmission is a problem in healthcare where patients are discharged from the hospital and then readmitted within a certain period of time, often within 30 days of their initial discharge. This is a costly and preventable problem that can negatively impact patients' health outcomes and quality of life. Causes of readmissions include inadequate care during initial hospitalization and poor discharge planning. Patients with chronic conditions, such as heart failure, diabetes, and respiratory disease, are at a particularly high risk of readmission. \n",
    "\n",
    "Hospital readmissions are also an important quality of care measure in healthcare. The Centers for Medicare and Medicaid Services (CMS) implemented a Hospital Readmissions Reduction Program (HRRP) in 2012, which financially penalizes hospitals with higher-than-expected readmission rates for certain conditions. The goal of this program is to incentivize hospitals to improve care coordination and reduce preventable readmissions.\n",
    "\n",
    "To reduce readmissions, interventions such as improved care coordination, enhanced patient education, and medication management are implemented.Additionally, involving patients and their caregivers in the discharge planning process and providing education about their condition and self-care management can also improve patient outcomes and reduce readmissions. These findings highlight the importance of implementing evidence-based strategies to reduce hospital readmissions and improve patient outcomes in healthcare.\n",
    "\n",
    "Machine learning and artificial intelligence (AI) algorithms are also used to predict which patients are at the highest risk of readmission and enable healthcare providers to intervene proactively to prevent readmissions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e941a04f",
   "metadata": {},
   "source": [
    "## 3. Data and Methods\n",
    "As a company, we have access to a dataset that contains patient information spanning over a period of ten years.([source](https://archive.ics.uci.edu/ml/datasets/Diabetes+130-US+hospitals+for+years+1999-2008)):\n",
    "\n",
    "**Information in the Dataset**\n",
    "\n",
    "- \"age\" - age bracket of the patient\n",
    "- \"time_in_hospital\" - days (from 1 to 14)\n",
    "- \"n_procedures\" - number of procedures performed during the hospital stay\n",
    "- \"n_lab_procedures\" - number of laboratory procedures performed during the hospital stay\n",
    "- \"n_medications\" - number of medications administered during the hospital stay\n",
    "- \"n_outpatient\" - number of outpatient visits in the year before a hospital stay\n",
    "- \"n_inpatient\" - number of inpatient visits in the year before the hospital stay\n",
    "- \"n_emergency\" - number of visits to the emergency room in the year before the hospital stay\n",
    "- \"medical_specialty\" - the specialty of the admitting physician\n",
    "- \"diag_1\" - primary diagnosis (Circulatory, Respiratory, Digestive, etc.)\n",
    "- \"diag_2\" - secondary diagnosis\n",
    "- \"diag_3\" - additional secondary diagnosis\n",
    "- \"glucose_test\" - whether the glucose serum came out as high (> 200), normal, or not performed\n",
    "- \"A1Ctest\" - whether the A1C level of the patient came out as high (> 7%), normal, or not performed\n",
    "- \"change\" - whether there was a change in the diabetes medication ('yes' or 'no')\n",
    "- \"diabetes_med\" - whether a diabetes medication was prescribed ('yes' or 'no')\n",
    "- \"readmitted\" - if the patient was readmitted at the hospital ('yes' or 'no') \n",
    "\n",
    "**Remarks on the data:**<br>\n",
    "The dataframe contains 25000 rows and 17 columns, with no missing values or duplicate rows. Most of the numeric columns exhibit positive skewness, likely due to a significant number of outliers, which totalled 11181. To prevent the loss of important information during analysis, we retained these outliers.\n",
    "\n",
    "**Methods**<br>\n",
    "Our exploratory data analysis involved various methodologies, including data cleaning, data visualization, statistical analysis, and machine learning algorithms. To clean the data, we used Pandas to handle missing values, and outliers, and transform variables as necessary. We also used Scikit-learn tools, such as One-Hot-Encoder, to prepare the data for machine learning algorithms. For visualization, we employed Matplotlib and Seaborn to create various plots, including barplots, lineplots, and heat maps, to identify patterns and relationships. Additionally, we utilized the Pingouin library for statistical analysis, including the Chi-square test to understand relationships between variables. For machine learning, we implemented various algorithms, such as k-Nearest Neighbors, Logistic Regression, and Random Forests, and evaluated the models based on accuracy, precision, recall, F1 score, and cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc137524",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d51c57aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pingouin as pg\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler, PowerTransformer\n",
    "from sklearn.compose import make_column_selector, ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, KFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, precision_recall_curve,\\\n",
    "     auc, roc_auc_score, roc_curve, confusion_matrix, ConfusionMatrixDisplay, RocCurveDisplay, DetCurveDisplay\n",
    "    \n",
    "\n",
    "    \n",
    "# Create custom graphics and theme\n",
    "custom_params = {'axes.spines.right':False,\n",
    "                'axes.spines.top':False,\n",
    "                'grid.color':'#dedede'}\n",
    "\n",
    "sns.set_theme(context='paper', style = 'ticks',\n",
    "             rc=custom_params, palette = 'colorblind', font_scale=1.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e361d1",
   "metadata": {},
   "source": [
    "We will create some functions that will aid our analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6b79863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function for explore summary statistics\n",
    "def stats(df):\n",
    "    \"\"\"\n",
    "    Function to explore a pandas DataFrame and return a summary table of each column.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df: pandas DataFrame\n",
    "        The DataFrame to be explored.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    result: pandas DataFrame\n",
    "        A summary table of each column containing its type, minimum and maximum values,\n",
    "        percentage of NaN values, number of values, and unique values.\n",
    "    \"\"\"\n",
    "    result = pd.DataFrame(columns = ['Type', 'Min', 'Max', 'Nan %', '# Values', 'Unique Values'])\n",
    "    for col, content in df.items:\n",
    "        values = []\n",
    "        values.append(content.dtype) # look for type\n",
    "        try:\n",
    "            values.append(content.min()) # minimum value\n",
    "            values.append(content.max()) # maximum value\n",
    "        except Exception:\n",
    "            values.append('None')\n",
    "            values.append('None')\n",
    "        values.append(df[col].isnull().sum()/len(df[col]) * 100) # find % of NaN\n",
    "        values.append(content.nunique()) # numbe rof unique values\n",
    "        values.append(content.unique()) # unique values for a column\n",
    "        \n",
    "        result.loc[col] = values\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7524e85",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
